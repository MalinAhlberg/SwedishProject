I have two testsuites for the mapping: one with short (3-10 words sentences),
where the words had been exchanges to known words of the same category.
I also had one with randomly picked sentences. the mapping restored 85% of the
nodes in the easy one, and 64% of the hard one. Since talbanken does not
give information about valency, the mapper needs to get this info from the
lexicon.

I created more testsuites for the other parts:
a list of words paired with the sentence number, to test the lexicon.
 (not really a list, but I can just test talbanken and get information about
  the sentence number)
one testsuite with 100 random sentences, no listing allowed
one testsuite with sentences without *,),- etc
one testsuite with uncomplicated sentences 
a way of easily extracting the bare sentences (without xml) from those

the testsuites are in the directory testsuites, in the README file
there is more info about them.
